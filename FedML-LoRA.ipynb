{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T19:40:33.097995Z","iopub.status.busy":"2023-06-01T19:40:33.09754Z","iopub.status.idle":"2023-06-01T19:40:33.106495Z","shell.execute_reply":"2023-06-01T19:40:33.105521Z","shell.execute_reply.started":"2023-06-01T19:40:33.097963Z"},"id":"5db35d05","trusted":true},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.optim import Adam\n","import loralib as lora\n","from transformers import DataCollatorForSeq2Seq, get_cosine_schedule_with_warmup\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n","from datasets import load_dataset\n","from transformers import BertConfig \n","from transformers import EncoderDecoderConfig \n","from transformers import DataCollatorWithPadding \n","from transformers import EncoderDecoderModel \n","from transformers import AutoTokenizer \n","from transformers import AutoModelForSequenceClassification \n","from transformers import CONFIG_MAPPING \n","from transformers import AutoConfig"]},{"cell_type":"markdown","metadata":{},"source":["## LoRA Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T19:40:33.108277Z","iopub.status.busy":"2023-06-01T19:40:33.107941Z","iopub.status.idle":"2023-06-01T19:40:33.124927Z","shell.execute_reply":"2023-06-01T19:40:33.123998Z","shell.execute_reply.started":"2023-06-01T19:40:33.108251Z"},"trusted":true},"outputs":[],"source":["## Set max matrix rank\n","lora_r = 4\n","\n","def make_lora_layer(layer, lora_r=4):\n","    new_layer = lora.Linear(\n","        in_features=layer.in_features,\n","        out_features=layer.out_features,\n","        bias=layer.bias is None,\n","        r=lora_r,\n","        merge_weights=False\n","    )\n","    \n","    new_layer.weight = nn.Parameter(layer.weight.detach())\n","    \n","    if layer.bias is not None:\n","        new_layer.bias = nn.Parameter(layer.bias.detach())\n","    \n","    return new_layer\n","\n","\n","def make_lora_replace(model, depth=1, path=\"\", verbose=True):\n","    if depth > 10:\n","        return\n","    depth += 1\n","        \n","    if isinstance(model, nn.Linear) and \"attention\" in path:\n","        if verbose:\n","            print(f\"Find linear {path}:{key} :\", type(module))\n","\n","        return make_lora_layer(model)\n","    \n","    for key in dir(model):\n","        module = getattr(model, key)\n","        module_type = type(module)\n","            \n","        if not isinstance(module, nn.Module) or module is model:\n","            continue\n","\n","        if isinstance(module, nn.Linear) and \"attention\" in path:\n","            layer = make_lora_layer(module)\n","            setattr(model, key, layer)\n","            if verbose:\n","                print(f\"Find linear {path}:{key} :\", type(module))\n","            \n","        elif isinstance(module, nn.ModuleList):\n","            for i, elem in enumerate(module):\n","                layer = make_lora_replace(elem, depth, path+\":\"+key+f\"[{i}]\", verbose=verbose)\n","                if layer is not None:\n","                    module[i] = layer\n","                \n","        elif isinstance(module, nn.ModuleDict):\n","            for module_key in list(module.keys()):\n","                layer = make_lora_replace(item, depth, path+\":\"+key+\":\"+module_key, verbose=verbose)\n","                if layer is not None:\n","                    module[module_key] = layer\n","                \n","        else:\n","            layer = make_lora_replace(module, depth, path+\":\"+key, verbose=verbose)\n","            if layer is not None:\n","                setattr(model, key, layer)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Fetch Data, Models"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T19:40:33.127477Z","iopub.status.busy":"2023-06-01T19:40:33.127106Z","iopub.status.idle":"2023-06-01T19:40:38.277349Z","shell.execute_reply":"2023-06-01T19:40:38.276128Z","shell.execute_reply.started":"2023-06-01T19:40:33.127445Z"},"trusted":true},"outputs":[],"source":["dataset_id, task, tok_train_fold, sentence1_key, num_labels, vocab_len = 'tweet_eval', 'emotion', 'train', 'text', 4, 30000\n","\n","dataset = load_dataset(dataset_id, task)\n","\n","USE_LORA = True\n","model_name = 'roberta-large'\n","batch_size = 16\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    model_name,\n","    num_labels=num_labels\n",")\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","collator = DataCollatorWithPadding(tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T19:40:38.279738Z","iopub.status.busy":"2023-06-01T19:40:38.279421Z","iopub.status.idle":"2023-06-01T19:40:41.366962Z","shell.execute_reply":"2023-06-01T19:40:41.365755Z","shell.execute_reply.started":"2023-06-01T19:40:38.279711Z"},"trusted":true},"outputs":[],"source":["if USE_LORA:\n","#     first_output = model(**collator([tokenizer('test')]))\n","\n","    make_lora_replace(model, verbose=True)\n","\n","#     final_output = model(**collator([tokenizer('test')]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T19:40:41.368419Z","iopub.status.busy":"2023-06-01T19:40:41.368124Z","iopub.status.idle":"2023-06-01T19:40:41.802046Z","shell.execute_reply":"2023-06-01T19:40:41.800754Z","shell.execute_reply.started":"2023-06-01T19:40:41.368394Z"},"trusted":true},"outputs":[],"source":["## Load omdel onto TPU/GPU\n","model = model.to(device)\n","# tokenizer = tokenizer.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["## Apply LoRA to model "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T19:40:41.80369Z","iopub.status.busy":"2023-06-01T19:40:41.803343Z","iopub.status.idle":"2023-06-01T19:40:41.821215Z","shell.execute_reply":"2023-06-01T19:40:41.820344Z","shell.execute_reply.started":"2023-06-01T19:40:41.80364Z"},"trusted":true},"outputs":[],"source":["lora_r = 4 ## Try different max matrix ranks for different results\n","\n","total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(f\"Total trainable parameters before LoRA: {total_trainable_params}\")\n","\n","## Apply LoRA\n","lora.mark_only_lora_as_trainable(model)\n","\n","total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(f\"Total trainable parameters after LoRA: {total_trainable_params}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T19:36:02.520585Z","iopub.status.busy":"2023-06-01T19:36:02.520179Z","iopub.status.idle":"2023-06-01T19:36:02.544401Z","shell.execute_reply":"2023-06-01T19:36:02.54318Z","shell.execute_reply.started":"2023-06-01T19:36:02.52055Z"},"trusted":true},"outputs":[],"source":["for name, param in model.named_parameters():\n","    if \"deberta\" not in name:\n","        print(name)\n","#             print(param.shape)\n","        param.requires_grad = True"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T19:36:02.546533Z","iopub.status.busy":"2023-06-01T19:36:02.545884Z","iopub.status.idle":"2023-06-01T19:36:02.554659Z","shell.execute_reply":"2023-06-01T19:36:02.553746Z","shell.execute_reply.started":"2023-06-01T19:36:02.546496Z"},"trusted":true},"outputs":[],"source":["# import wandb\n","\n","# wandb.init(project='Lora')"]},{"cell_type":"markdown","metadata":{},"source":["## Process Training Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T18:54:04.206953Z","iopub.status.busy":"2023-06-01T18:54:04.206664Z","iopub.status.idle":"2023-06-01T18:54:04.449107Z","shell.execute_reply":"2023-06-01T18:54:04.447991Z","shell.execute_reply.started":"2023-06-01T18:54:04.206928Z"},"trusted":true},"outputs":[],"source":["def preprocess_function(examples):\n","    return tokenizer(examples[sentence1_key], truncation=True, padding=True)\n","\n","encoded_dataset = dataset.map(preprocess_function, batched=True)\n","\n","encoded_dataset = encoded_dataset.remove_columns(['text'])\n","\n","dataloaders = {\n","    key: DataLoader(ds, shuffle=True, collate_fn=collator, num_workers=2, batch_size=batch_size) for key, ds in encoded_dataset.items()\n","}"]},{"cell_type":"markdown","metadata":{},"source":["## Batching Helpers"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T18:54:04.450623Z","iopub.status.busy":"2023-06-01T18:54:04.450341Z","iopub.status.idle":"2023-06-01T18:54:04.458355Z","shell.execute_reply":"2023-06-01T18:54:04.457474Z","shell.execute_reply.started":"2023-06-01T18:54:04.450599Z"},"trusted":true},"outputs":[],"source":["def predict_loader(dataloader):\n","    model.eval()\n","    res = []\n","    labels = []\n","    \n","    for batch in tqdm(dataloader):\n","        batch = batch_device(batch)\n","        output = model(**batch).logits.argmax(dim=-1).detach().cpu().numpy()\n","        res.extend(output)\n","        labels.extend(batch.labels.detach().cpu().numpy())\n","            \n","    return(res, labels)\n","\n","\n","def batch_device(batch):\n","    for key in list(batch.keys()):\n","        batch[key] = batch[key].to(device)\n","        \n","    return(batch)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T18:54:04.459686Z","iopub.status.busy":"2023-06-01T18:54:04.459399Z","iopub.status.idle":"2023-06-01T18:54:04.478716Z","shell.execute_reply":"2023-06-01T18:54:04.477749Z","shell.execute_reply.started":"2023-06-01T18:54:04.459649Z"},"trusted":true},"outputs":[],"source":["# wandb.watch(model)"]},{"cell_type":"markdown","metadata":{},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T18:54:04.480247Z","iopub.status.busy":"2023-06-01T18:54:04.479876Z","iopub.status.idle":"2023-06-01T18:59:20.245901Z","shell.execute_reply":"2023-06-01T18:59:20.244054Z","shell.execute_reply.started":"2023-06-01T18:54:04.480222Z"},"trusted":true},"outputs":[],"source":["from IPython.display import clear_output\n","from tqdm.autonotebook import tqdm\n","from sklearn.metrics import f1_score\n","\n","lr = 2e-5\n","if USE_LORA:\n","    lr = 2e-4\n","\n","optimizer = Adam([param for param in model.parameters() if param.requires_grad], lr=lr)\n","steps = len(dataloaders['train'])\n","epochs = 15\n","scheduler = get_cosine_schedule_with_warmup(optimizer, steps * 1, steps * epochs)\n","best_f1 = 0\n","\n","\n","for i in range(epochs):\n","    model.train()\n","    losses = []\n","    for batch in tqdm(dataloaders['train']):\n","        batch = batch_device(batch)\n","        \n","        optimizer.zero_grad()\n","        output = model(**batch)\n","\n","        output.loss.backward()\n","#         wandb.log({\n","#             \"train/loss\": output.loss.detach().cpu().numpy()\n","#         })\n","        \n","        optimizer.step()\n","        scheduler.step()\n","    \n","    res, labels = predict_loader(dataloaders['validation'])\n","    res = np.array(res) \n","    labels = np.array(labels)\n","    f1 = f1_score(labels, res, average='micro')\n","#     wandb.log({\n","#         \"eval/f1\": f1\n","#     })\n","#     print(f1)\n","    \n","    if f1 > best_f1:\n","        best_f1 = f1\n","        checkpoint_path = \"best_lora_checkpoint.pth\"\n","        \n","        if USE_LORA:\n","            torch.save(lora.lora_state_dict(model), checkpoint_path)\n","        else:\n","            torch.save(model.state_dict(), checkpoint_path)\n","\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30497,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":4}

# LLM-Data-Privacy

The financial industry has experienced significant strides in Natural Language Processing (NLP) facilitated by Language Model (LM) technologies. However, the escalating concerns regarding data privacy present a formidable barrier to the ongoing enhancement of these models. A notable challenge involves potential adversarial attackers exploiting the weight of Language Models trained by individual banks, thereby jeopardizing user data confidentiality.

This project seeks to address the critical issue of data privacy in Language Model training within the financial sector by proposing and implementing a Privacy-Preserving Federated Learning Protocol.
The primary goal is to establish a collaborative framework that empowers multiple banks to collectively train a Language Model without the necessity to share or access each other's private and sensitive data. Departing from the conventional practice of sharing precise model weights, this innovative framework facilitates the exchange of "biased weights." This approach thwarts third-party attempts to infer training data, thereby safeguarding the confidentiality of sensitive information.

The core principle of this federated learning approach is to ensure that the Language Model remains robust, accurate, and reflective of the diverse financial data landscape. Simultaneously, it addresses the privacy concerns inherent to individual financial institutions. By mitigating data privacy risks, this project strives to foster an environment where advancements in NLP can continue to flourish in the financial sector, promoting collaborative innovation while upholding the highest standards of data security.

![image](https://github.com/Michonster/FinLLM-DP-Lora/assets/83566627/700b1274-2bec-41c8-a717-57d1b7036165)

Process and planning for this project is based on this paper: https://arxiv.org/abs/2312.17493
